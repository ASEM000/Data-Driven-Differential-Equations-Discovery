{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DE discovery from data (ongoing project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate training data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78a49ae80cd4753a74789bb0ac89aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate validation data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b13be948d145e8a0613a07c323ccf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def RK4n(odefun,ics,h,span,degree):\n",
    "    \n",
    "    N= int( (span[1]-span[0])/h )\n",
    "    \n",
    "    tY = np.zeros((N+1,degree+1),dtype='float64')\n",
    "    tY[0,1:] = ics\n",
    "    \n",
    "    \n",
    "    for  i in range(N):\n",
    "        tY[i+1,0] = tY[i,0] + h\n",
    "        k1= odefun(tY[i,0]       , tY[i,1:])\n",
    "        k2= odefun(tY[i,0] +(h/2), tY[i,1:] +(h*k1)/2 )\n",
    "        k3 = odefun(tY[i,0] +(h/2), tY[i,1:] +(h*k2)/2)\n",
    "        k4 = odefun(tY[i,0] +(h)  , tY[i,1:] +(h*k3))\n",
    "        tY[i+1,1:] = tY[i,1:] + h*(1/6) * (k1+2*k2+2*k3+k4)\n",
    "        \n",
    "    return tY[:,0],tY[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#training\n",
    "print('Generate training data')\n",
    "\n",
    "samples = 1000\n",
    "\n",
    "np.random.seed(0)\n",
    "train_xx = np.zeros((samples,1,50,50,1),dtype='float')\n",
    "train_yy = np.zeros((samples,1,1,3))\n",
    "d2_train = np.random.randint(low=-5,high=1,size=(samples,1,3)) - np.round(np.random.rand(samples,1,3),1)\n",
    "ic_train = np.random.randint(low=0,high=5,size=(samples,2))\n",
    "from functools import partial \n",
    "\n",
    "def partial_ode_fun(d4,x,y):\n",
    "        #candidate library\n",
    "        A = np.zeros((2,3))\n",
    "        A[0,1]=1;A[1] = d4\n",
    "        V = np.array([y[0],y[1],x]) \n",
    "        AV =np.matmul(A,V)\n",
    "        return AV\n",
    "\n",
    "for i in tqdm(range(samples)):\n",
    "    ode_fun = partial(partial_ode_fun,d2_train[i])\n",
    "    sol  = RK4n(ode_fun,ics=ic_train[i],h=1e-3,span=np.array([0,2.5]),degree =2)\n",
    "    train_xx[i] = ((sol[1][:-1,0])).reshape(1,50,50,1)\n",
    "    train_yy[i,0] = d2_train[i,-1]\n",
    "    \n",
    "\n",
    "\n",
    "#scaling\n",
    "\n",
    "x_min,x_max = np.min(train_xx),np.max(train_xx)\n",
    "train_x = (train_xx-x_min)/((x_max-x_min)+1e-3)\n",
    "\n",
    "y_min,y_max = np.min(train_yy),np.max(train_yy)\n",
    "train_y = (train_yy-y_min)/((y_max-y_min)+1e-3)\n",
    "\n",
    "\n",
    "#validation\n",
    "\n",
    "samples = 100\n",
    "np.random.seed(10)\n",
    "val_xx = np.zeros((samples,1,50,50,1),dtype='float')\n",
    "val_yy = np.zeros((samples,1,1,3))\n",
    "d2_val = np.random.randint(low=-5,high=1,size=(samples,1,3)) - np.round(np.random.rand(samples,1,3),1)\n",
    "ic_val = np.random.randint(low=0,high=5,size=(samples,2))\n",
    "\n",
    "print('Generate validation data')\n",
    "\n",
    "for i in tqdm(range(samples)):\n",
    "    ode_fun = partial(partial_ode_fun,d2_val[i])\n",
    "    sol  = RK4n(ode_fun,ics=ic_val[i],h=1e-3,span=np.array([0,2.5]),degree =2)\n",
    "    val_xx[i] = ((sol[1][:-1,0])).reshape(1,50,50,1)\n",
    "    val_yy[i,0] = d2_val[i,-1]\n",
    "    \n",
    "\n",
    "\n",
    "#scaling\n",
    "\n",
    "# x_min,x_max = np.min(train_xx),np.max(train_xx)\n",
    "val_x = (val_xx-x_min)/((x_max-x_min)+1e-3)\n",
    "\n",
    "# y_min,y_max = np.min(train_yy),np.max(train_yy)\n",
    "val_y = (val_yy-y_min)/((y_max-y_min)+1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow\n",
    "\n",
    "def conv(x,f,k):\n",
    "    x = TimeDistributed(Conv2D(f,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def dense_block(tensor, f, r,k):\n",
    "    for _ in range(r):\n",
    "        x = conv(tensor, f=4*f, k=1)\n",
    "        x = conv(x, f=f, k=k)\n",
    "        tensor = Concatenate()([tensor, x])\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def transition(x,s):\n",
    "    ff = int(tensorflow.keras.backend.int_shape(x)[-1] * 0.5)\n",
    "    m0 = TimeDistributed(Conv2D(ff,(1,1),strides=2*s,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return m0\n",
    "\n",
    "def dfn():\n",
    "    \n",
    "    k=3\n",
    "    s=1;\n",
    "    LR=1e-4\n",
    "    \n",
    "    r1,r2,r3 = 2 , 4 ,8\n",
    "    f0,f1,f2,f3 = 128,32,32,32\n",
    "    l1,l2 = 128 ,64\n",
    "\n",
    "    x = Input(shape=(1,50,50, 1))\n",
    "    c0 = TimeDistributed(Conv2D(f0,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "########################################################################################################    \n",
    "    e1 = dense_block(c0,f1,r=r1,k=k);m1 = transition(e1,s)\n",
    "    e2 = dense_block(m1,f2,r=r2,k=k);m2 = transition(e2,s)\n",
    "    e3 = dense_block(m2,f3,r=r3,k=k);\n",
    "########################################################################################################\n",
    "    e = ConvLSTM2D(l1,(2,2),padding='same',return_sequences=True)(e3)\n",
    "    b = ConvLSTM2D(l2,(2,2),padding='same',return_sequences=True)(e)\n",
    "########################################################################################################\n",
    "    b = TimeDistributed(Flatten())(b)\n",
    "    d3 =TimeDistributed(Dense(3,activation='linear'))(b)\n",
    "    d3 =TimeDistributed(Reshape((1,3)))(d3)\n",
    "    model = Model(x,d3)\n",
    "    optimizer = Adam(learning_rate=LR)\n",
    "    model.compile(loss='mae',optimizer=optimizer,metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "model = dfn()\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0401 - mse: 0.0039 - val_loss: 0.0434 - val_mse: 0.0045\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.0403 - mse: 0.0039 - val_loss: 0.0434 - val_mse: 0.0041\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0401 - mse: 0.0039 - val_loss: 0.0472 - val_mse: 0.0050\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0417 - mse: 0.0040 - val_loss: 0.0454 - val_mse: 0.0047\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.0401 - mse: 0.0038 - val_loss: 0.0498 - val_mse: 0.0055\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0414 - mse: 0.0040\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0414 - mse: 0.0040 - val_loss: 0.0436 - val_mse: 0.0043\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.0382 - mse: 0.0036 - val_loss: 0.0436 - val_mse: 0.0045\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.0380 - mse: 0.0036 - val_loss: 0.0434 - val_mse: 0.0044\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.0374 - mse: 0.0036 - val_loss: 0.0460 - val_mse: 0.0050\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0375 - mse: 0.0036 - val_loss: 0.0440 - val_mse: 0.0045\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0376 - mse: 0.0035 - val_loss: 0.0451 - val_mse: 0.0044\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0376 - mse: 0.0035 - val_loss: 0.0419 - val_mse: 0.0042\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0380 - mse: 0.0036 - val_loss: 0.0459 - val_mse: 0.0048\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0377 - mse: 0.0036\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0377 - mse: 0.0036 - val_loss: 0.0426 - val_mse: 0.0043\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.0356 - mse: 0.0034 - val_loss: 0.0419 - val_mse: 0.0042\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0354 - mse: 0.0033 - val_loss: 0.0416 - val_mse: 0.0041\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0359 - mse: 0.0034 - val_loss: 0.0428 - val_mse: 0.0043\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0355 - mse: 0.0034 - val_loss: 0.0424 - val_mse: 0.0042\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0351 - mse: 0.0033 - val_loss: 0.0426 - val_mse: 0.0045\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0354 - mse: 0.0034 - val_loss: 0.0419 - val_mse: 0.0041\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0356 - mse: 0.0033 - val_loss: 0.0423 - val_mse: 0.0042\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0352 - mse: 0.0033 - val_loss: 0.0425 - val_mse: 0.0044\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0350 - mse: 0.0032 - val_loss: 0.0413 - val_mse: 0.0041\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0351 - mse: 0.0033\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0351 - mse: 0.0033 - val_loss: 0.0412 - val_mse: 0.0040\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0345 - mse: 0.0032 - val_loss: 0.0421 - val_mse: 0.0042\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0341 - mse: 0.0032 - val_loss: 0.0415 - val_mse: 0.0041\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0344 - mse: 0.0033 - val_loss: 0.0420 - val_mse: 0.0042\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0344 - mse: 0.0032 - val_loss: 0.0427 - val_mse: 0.0044\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0343 - mse: 0.0032 - val_loss: 0.0418 - val_mse: 0.0042\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0341 - mse: 0.0032 - val_loss: 0.0414 - val_mse: 0.0041\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0339 - mse: 0.0032 - val_loss: 0.0414 - val_mse: 0.0042\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0341 - mse: 0.0032 - val_loss: 0.0413 - val_mse: 0.0042\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0347 - mse: 0.0032 - val_loss: 0.0415 - val_mse: 0.0041\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0339 - mse: 0.0032 - val_loss: 0.0414 - val_mse: 0.0042\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0341 - mse: 0.0032 - val_loss: 0.0416 - val_mse: 0.0042\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0339 - mse: 0.0032\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0339 - mse: 0.0032 - val_loss: 0.0415 - val_mse: 0.0041\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0337 - mse: 0.0032 - val_loss: 0.0417 - val_mse: 0.0042\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0335 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0041\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0335 - mse: 0.0032 - val_loss: 0.0413 - val_mse: 0.0042\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0335 - mse: 0.0032 - val_loss: 0.0416 - val_mse: 0.0042\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.0334 - mse: 0.0031 - val_loss: 0.0413 - val_mse: 0.0042\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.0335 - mse: 0.0031 - val_loss: 0.0418 - val_mse: 0.0043\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0334 - mse: 0.0031\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0334 - mse: 0.0031 - val_loss: 0.0416 - val_mse: 0.0042\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0335 - mse: 0.0031 - val_loss: 0.0414 - val_mse: 0.0042\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0333 - mse: 0.0031 - val_loss: 0.0415 - val_mse: 0.0042\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0332 - mse: 0.0031 - val_loss: 0.0413 - val_mse: 0.0042\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0332 - mse: 0.0031 - val_loss: 0.0413 - val_mse: 0.0042\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0332 - mse: 0.0031 - val_loss: 0.0413 - val_mse: 0.0042\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0333 - mse: 0.0031 - val_loss: 0.0413 - val_mse: 0.0041\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0332 - mse: 0.0031\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0332 - mse: 0.0031 - val_loss: 0.0413 - val_mse: 0.0042\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0331 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0041\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0331 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0331 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0041\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0331 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0041\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0331 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0041\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0331 - mse: 0.0031\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.0331 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0041\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0331 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0041\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0041\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0041\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0041\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0413 - val_mse: 0.0042\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0330 - mse: 0.0031\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0041\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0041\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0330 - mse: 0.0031\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0330 - mse: 0.0031\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0330 - mse: 0.0031\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0330 - mse: 0.0031\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0411 - val_mse: 0.0042\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.0330 - mse: 0.0031 - val_loss: 0.0412 - val_mse: 0.0042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12c3347adc8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv_logger = tensorflow.keras.callbacks.CSVLogger('train step=10 12x12.log')\n",
    "# early_stopping = tensorflow.keras.callbacks.EarlyStopping(monitor='loss',min_delta=5e-5, patience=5, verbose=1, mode='auto',baseline=None, restore_best_weights=False)\n",
    "reduce_lr_callback = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor = 'loss',factor = 0.5,patience = 5,verbose = 1,cooldown=1,min_delta = 1e-4,min_lr=1e-8 )\n",
    "# model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint('step=100 12x12.h5', monitor='loss', verbose=1, save_best_only=False,save_weights_only=False, mode='auto', save_freq='epoch',)\n",
    "model.fit(train_x,train_y,\n",
    "          validation_data=(val_x,val_y),\n",
    "          epochs=100,\n",
    "          callbacks=[reduce_lr_callback],\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "\n",
    "def partial_ode_fun(d4,x,y):\n",
    "        #candidate library\n",
    "        A = np.zeros((2,3))\n",
    "        A[0,1]=1;A[1,:] = d4\n",
    "        V = np.array([y[0],y[1],x]) \n",
    "        AV =np.matmul(A,V)\n",
    "        return AV\n",
    "\n",
    "def solve_from_prediction(coeffs,ics):\n",
    "    ode_fun = partial(partial_ode_fun,coeffs)\n",
    "    sol  = RK4n(ode_fun,ics=ics,h=1e-3,span=np.array([0,2.5]),degree =2)\n",
    "    return ((sol[1][:-1,0]))\n",
    "\n",
    "# j = 120\n",
    "\n",
    "# coeffs = ( model.predict(train_x[[j]]) * ((y_max-y_min)+1e-3) ) + y_min\n",
    "# prediction = solve_from_prediction(coeffs[0,0,0])\n",
    "\n",
    "# plt.plot(prediction,'-r')\n",
    "# plt.plot(xx[j].reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"]})\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 72\n",
    "mpl.rcParams.update({'font.size': 35})\n",
    "mpl.rcParams['axes.linewidth'] = 2\n",
    "from matplotlib import ticker\n",
    "formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_scientific(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate test data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1408ce77d034eba8b8480634b8376b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "samples = 50\n",
    "np.random.seed(50)\n",
    "test_xx = np.zeros((samples,1,50,50,1),dtype='float')\n",
    "test_yy = np.zeros((samples,1,1,3))\n",
    "d2_test = np.random.randint(low=-5,high=1,size=(samples,1,3)) - np.round(np.random.rand(samples,1,3),1)\n",
    "ic_test = np.random.randint(low=0,high=5,size=(samples,2))\n",
    "\n",
    "print('Generate test data')\n",
    "\n",
    "for i in tqdm(range(samples)):\n",
    "    ode_fun = partial(partial_ode_fun,d2_test[i])\n",
    "    sol  = RK4n(ode_fun,ics=ic_test[i],h=1e-3,span=np.array([0,2.5]),degree =2)\n",
    "    test_xx[i] = ((sol[1][:-1,0])).reshape(1,50,50,1)\n",
    "    test_yy[i,0] = d2_test[i,-1]\n",
    "    \n",
    "\n",
    "\n",
    "#scaling\n",
    "\n",
    "x_min,x_max = np.min(train_xx),np.max(train_xx)\n",
    "test_x = (test_xx-x_min)/((x_max-x_min)+1e-3)\n",
    "\n",
    "y_min,y_max = np.min(train_yy),np.max(train_yy)\n",
    "test_y = (test_yy-y_min)/((y_max-y_min)+1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1, 50, 50, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"]})\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "mpl.rcParams.update({'font.size': 20})\n",
    "mpl.rcParams['axes.linewidth'] = 2\n",
    "from matplotlib import ticker\n",
    "formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_scientific(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2365cb65aa8546a3841dd679d2063e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='j', max=49), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider,interact\n",
    "from IPython.display import Math\n",
    "\n",
    "slider = IntSlider(low=0,max=samples-1,value=0)\n",
    "noise = 0.00\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "@interact(j=slider)\n",
    "def show(j):\n",
    "    \n",
    "    a,b,c = -d2_test[j][0]\n",
    "    \n",
    "    coeffs = ( model.predict(test_x[[j]]+np.random.rand(50,50,1)*noise) * ((y_max-y_min)+1e-3) ) + y_min\n",
    "    prediction = solve_from_prediction(coeffs[0,0,0],ic_test[j])\n",
    "    \n",
    "    k,l,m = -coeffs[0,0,0]\n",
    "#     l = np.round(l,2)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(np.arange(0,2.5,1e-3),prediction,'--k')\n",
    "    plt.plot(np.arange(0,2.5,1e-3),test_xx[j].reshape(-1,1),'-r')\n",
    "    plt.xlabel('$x$');plt.ylabel('$y$')\n",
    "    MSE = sklearn.metrics.mean_squared_error(test_xx[j].reshape(-1,1),prediction)\n",
    "    plt.legend([f'$Prediction$','$RK4 \\ result$'])\n",
    "    plt.title('$Test \\ samples \\ prediction$')\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.yticks(np.arange(-6,12,1))\n",
    "    plt.text(0.1,8,'$correct \\  \\ \\   \\ \\ DE : {dy^2\\over dx^2} + $' + f'${b}$'  + '${dy\\over dx} + $' +f'${a} $'  + '${y} + $' +f'${c}$' '${x} + $' )\n",
    "    plt.text(0.1,4,'$predicted \\  DE : {dy^2\\over dx^2} + $' + f'${l}$'  + '${dy\\over dx} + $' +f'${k} $'  + '${y} + $' +f'${m}$' '${x}$' )\n",
    "    plt.text(0.1,0,f'$Nosie= \\ $' +  f'${noise*100}$' + f'$\\%$' )\n",
    "    plt.text(0.1,-4,f'$MSE= \\ $' +  f'${np.round(MSE*10**3,3)}e-3$'  )\n",
    "    plt.yticks([]);plt.xticks([])\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 4.4 x + 2.4 y{\\left(x \\right)} + 5.6 \\frac{d}{d x} y{\\left(x \\right)} + \\frac{d^{2}}{d x^{2}} y{\\left(x \\right)}$"
      ],
      "text/plain": [
       "4.4*x + 2.4*y(x) + 5.6*Derivative(y(x), x) + Derivative(y(x), (x, 2))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x =sp.symbols('x')\n",
    "y = sp.Function('y')\n",
    "#expression of DE\n",
    "\n",
    "j = 10\n",
    "\n",
    "a,b,c = -d2_train[j][0]\n",
    "\n",
    "expr = sp.Derivative(y(x),x,x) + b*sp.Derivative(y(x),x) + a* y(x)+c*x \n",
    "expr\n",
    "# solution of DE\n",
    "sol_exact= sp.dsolve(expr, y(x),\n",
    " ics={y(0):ic_train[j][0],\n",
    " y(x).diff(x).subs(x, 0): ic_train[j][1],\n",
    " })\n",
    "sol_exact_func=sp.lambdify(x,sol_exact.rhs)\n",
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.4, -5.6, -4.4]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_yy[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12c3b867988>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sympy_res = [ sol_exact_func(i) for i in np.arange(0,2.5,1e-3)]\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(np.arange(0,2.5,1e-3),sympy_res,'-r')\n",
    "plt.plot(np.arange(0,2.5,1e-3),train_xx[j].reshape(-1,1),'--k')\n",
    "plt.legend(['$Sympy$','$RK4$'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
